{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project Report\"\n",
    "subtitle: Seoulmates\n",
    "author: Christine Kim, Christine Lee, Zindeh Scere, Seoyeon Yoon\n",
    "date: 12/04/2023\n",
    "number-sections: true\n",
    "abstract: _The ABSTRACT is to be in fully-justified italicized text at the top of the report, below the author information. The abstract section must summarise the four questions answered in the report, and the recommendations to the stakeholders based on the analysis. You may also briefly mention the results of the analysis that connect the questions to the recommendations. However, the abstract must not be more than 200 words in length_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: true\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5ee91",
   "metadata": {},
   "source": [
    "## Length of the report {-}\n",
    "The length of the report must be no more than 15 pages, when printed as PDF. However, there is no requirement on the minimum number of pages.\n",
    "\n",
    "**Delete this section from the report, when using this template.** \n",
    "\n",
    "You may put additional stuff as Appendix. You may refer to the Appendix in the main report to support your arguments. However, your appendix is unlikely to be checked while grading, unless the grader deems it necessary. The appendix and references will not be included in the page count, and there is no limit on the length of the appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186dcc6d",
   "metadata": {},
   "source": [
    "## Code should be put separately in the code template {-}\n",
    "Your report should be in a research-paper like style. If there is something that can only be explained by showing the code, then you may put it, otherwise do not put the code in the report. We will check your code in the code template. \n",
    "\n",
    "However, feel free to write code that prints output and then hide the code using the *yaml* setting as shown in an example below *(in the EDA section)*\n",
    "\n",
    "**Delete this section from the report, when using this template.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Background / Motivation\n",
    "\n",
    "What motivated you to work on this problem?\n",
    "\n",
    "Mention any background about the problem, if it is required to understand your analysis later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848b0a1",
   "metadata": {},
   "source": [
    "As avid travelers who are enthusiastic about finding decent accommodations, we all have experience with using Airbnb. In recent years, people have been looking for options other than traditional hotels and beds and breakfasts, and Airbnb’s popularity has surged during a digital age with technology. Therefore, we want explore and analyze the trends that appear within Airbnb’s datasets within Chicago, IL, as it is somewhere close to all of us at Northwestern. Through this analysis, we hope to understand the perspectives of and provide recommendations to Airbnb hosts and Airbnb customers in the city of Chicago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff1421",
   "metadata": {},
   "source": [
    "## Problem statement \n",
    "\n",
    "Describe your four questions. Articulate your questions using absolutely no jargon. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae1667",
   "metadata": {},
   "source": [
    "1. What is the correlation between the Proximity from the City and the Price of the listing?\n",
    "2. Are there associations between Amenities and the Price of the listing?\n",
    "3. Are there associations between Host Attributes and Booking Satisfaction\n",
    "4. How are Seasonal trends related to Pricing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7b95f",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "What data did you use? Provide details about your data. Include links to data if you are using open-access data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745a50a",
   "metadata": {},
   "source": [
    "Chicago Airbnb Data: http://insideairbnb.com/get-the-data/\n",
    "- Listings\n",
    "    - Summary information and metrics for listings in Chicago, collected on 9/12/2023.\n",
    "- Calendar\n",
    "    - Quarterly data for the last 12 months, showing each date and statuses (availability, price) of a subset of listings on that date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c255035",
   "metadata": {},
   "source": [
    "## Stakeholders\n",
    "Who cares? If you are successful, what difference will it make to them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93053c0",
   "metadata": {},
   "source": [
    "### Primary Stakeholders\n",
    "#### Hosts\n",
    "- Main stakeholders\n",
    "- Pricing strategies, property types, amenities to optimize their listings for better occupancy and revenue\n",
    "\n",
    "#### Guests\n",
    "- Pricing trends, the neighborhoods with high occupancy rates, and the types of properties available\n",
    "- Find the best accommodations in Chicago that meet their needs and budgets\n",
    "\n",
    "### Secondary Stakeholders\n",
    "#### Neighbors\n",
    "- Residential trends and advocacy around rental laws in local neighborhoods.\n",
    "- Make decisions around the potential impact Airbnbs may have in their neighborhoods\n",
    "\n",
    "#### City of Chicago\n",
    "- Generate revenue through more tourism\n",
    "- Regulators informed of impact of short-term rentals on different neighborhoods\n",
    "- Influence policies around creating laws to maintain access to residential housing\n",
    "\n",
    "#### Real Estate Investors\n",
    "- Investors looking to buy property\n",
    "- Profitability and other dynamics of short-term rentals in different neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "In a tabular form, show the distribution of values of each variable used in the analysis - for both categorical and continuous variables. Distribution of a categorical variable must include the number of missing values, the number of unique values, the frequency of all its levels. If a categorical variable has too many levels, you may just include the counts of the top 3-5 levels. \n",
    "\n",
    "Were there any potentially incorrect values of variables that required cleaning? If yes, how did you clean them? \n",
    "\n",
    "Did your analysis require any other kind of data preparation before it was ready to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb527913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244bbef5",
   "metadata": {},
   "source": [
    "### Airbnb Listings \n",
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f2882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.897704</td>\n",
       "      <td>-87.666005</td>\n",
       "      <td>181.431881</td>\n",
       "      <td>98.177426</td>\n",
       "      <td>4.763786</td>\n",
       "      <td>4.807012</td>\n",
       "      <td>4.757745</td>\n",
       "      <td>4.849218</td>\n",
       "      <td>4.862881</td>\n",
       "      <td>4.766341</td>\n",
       "      <td>4.683382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.062416</td>\n",
       "      <td>0.044503</td>\n",
       "      <td>206.919906</td>\n",
       "      <td>8.874949</td>\n",
       "      <td>0.373710</td>\n",
       "      <td>0.333659</td>\n",
       "      <td>0.379777</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.329447</td>\n",
       "      <td>0.349515</td>\n",
       "      <td>0.405023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.650640</td>\n",
       "      <td>-87.847160</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.867065</td>\n",
       "      <td>-87.690289</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.901555</td>\n",
       "      <td>-87.662915</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>4.940000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>4.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.940460</td>\n",
       "      <td>-87.634164</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>4.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.022200</td>\n",
       "      <td>-87.536550</td>\n",
       "      <td>7585.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          latitude    longitude        price  host_response_rate  \\\n",
       "count  5050.000000  5050.000000  5050.000000         5050.000000   \n",
       "mean     41.897704   -87.666005   181.431881           98.177426   \n",
       "std       0.062416     0.044503   206.919906            8.874949   \n",
       "min      41.650640   -87.847160    12.000000            0.000000   \n",
       "25%      41.867065   -87.690289    86.000000          100.000000   \n",
       "50%      41.901555   -87.662915   132.000000          100.000000   \n",
       "75%      41.940460   -87.634164   213.000000          100.000000   \n",
       "max      42.022200   -87.536550  7585.000000          100.000000   \n",
       "\n",
       "       review_scores_rating  review_scores_accuracy  \\\n",
       "count           5050.000000             5050.000000   \n",
       "mean               4.763786                4.807012   \n",
       "std                0.373710                0.333659   \n",
       "min                1.000000                1.000000   \n",
       "25%                4.700000                4.760000   \n",
       "50%                4.860000                4.900000   \n",
       "75%                4.970000                4.980000   \n",
       "max                5.000000                5.000000   \n",
       "\n",
       "       review_scores_cleanliness  review_scores_checkin  \\\n",
       "count                5050.000000            5050.000000   \n",
       "mean                    4.757745               4.849218   \n",
       "std                     0.379777               0.326767   \n",
       "min                     1.000000               1.000000   \n",
       "25%                     4.690000               4.830000   \n",
       "50%                     4.860000               4.940000   \n",
       "75%                     4.980000               5.000000   \n",
       "max                     5.000000               5.000000   \n",
       "\n",
       "       review_scores_communication  review_scores_location  \\\n",
       "count                  5050.000000             5050.000000   \n",
       "mean                      4.862881                4.766341   \n",
       "std                       0.329447                0.349515   \n",
       "min                       1.000000                1.000000   \n",
       "25%                       4.860000                4.700000   \n",
       "50%                       4.960000                4.880000   \n",
       "75%                       5.000000                4.970000   \n",
       "max                       5.000000                5.000000   \n",
       "\n",
       "       review_scores_value  \n",
       "count          5050.000000  \n",
       "mean              4.683382  \n",
       "std               0.405023  \n",
       "min               1.000000  \n",
       "25%               4.620000  \n",
       "50%               4.780000  \n",
       "75%               4.890000  \n",
       "max               5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "listings = pd.read_csv('listings_filtered.csv')\n",
    "continuous_var = listings.iloc[:, np.r_[2:5, 6, 8, 12:19]]\n",
    "continuous_var.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12f1c8",
   "metadata": {},
   "source": [
    "#### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c94cfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_location</th>\n",
       "      <th>wifi_amenities</th>\n",
       "      <th>bathroom_amenities</th>\n",
       "      <th>kitchen_amenities</th>\n",
       "      <th>leisure_amenities</th>\n",
       "      <th>laundry_amenities</th>\n",
       "      <th>...</th>\n",
       "      <th>outdoor_amenities</th>\n",
       "      <th>luxury_amenities</th>\n",
       "      <th>family_amenities</th>\n",
       "      <th>bedroom_amenities</th>\n",
       "      <th>pet_amenities</th>\n",
       "      <th>convenience_amenities</th>\n",
       "      <th>cleaning_amenities</th>\n",
       "      <th>service_amenities</th>\n",
       "      <th>smoking_amenities</th>\n",
       "      <th>work_amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>12</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>3</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>6</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>2</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>6</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5050 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accommodates  host_response_time host_is_superhost  \\\n",
       "0                1      within an hour                 t   \n",
       "1                2      within an hour                 t   \n",
       "2                4      within an hour                 t   \n",
       "3                3  within a few hours                 t   \n",
       "4                6  within a few hours                 t   \n",
       "...            ...                 ...               ...   \n",
       "5045            12      within an hour                 f   \n",
       "5046             3  within a few hours                 f   \n",
       "5047             6      within an hour                 t   \n",
       "5048             2  within a few hours                 f   \n",
       "5049             6      within an hour                 f   \n",
       "\n",
       "     host_identity_verified host_location  wifi_amenities  bathroom_amenities  \\\n",
       "0                         t   Chicago, IL               1                   1   \n",
       "1                         t   Chicago, IL               1                   1   \n",
       "2                         t   Chicago, IL               1                   1   \n",
       "3                         t   Chicago, IL               1                   1   \n",
       "4                         t   Chicago, IL               1                   1   \n",
       "...                     ...           ...             ...                 ...   \n",
       "5045                      t   Chicago, IL               1                   1   \n",
       "5046                      t   Chicago, IL               1                   1   \n",
       "5047                      t   Chicago, IL               1                   1   \n",
       "5048                      t   Chicago, IL               1                   0   \n",
       "5049                      t   Chicago, IL               1                   1   \n",
       "\n",
       "      kitchen_amenities  leisure_amenities  laundry_amenities  ...  \\\n",
       "0                     1                  1                  1  ...   \n",
       "1                     1                  1                  1  ...   \n",
       "2                     1                  1                  1  ...   \n",
       "3                     1                  1                  1  ...   \n",
       "4                     1                  1                  1  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "5045                  1                  1                  1  ...   \n",
       "5046                  1                  1                  1  ...   \n",
       "5047                  1                  1                  1  ...   \n",
       "5048                  1                  1                  1  ...   \n",
       "5049                  1                  1                  1  ...   \n",
       "\n",
       "      outdoor_amenities  luxury_amenities  family_amenities  \\\n",
       "0                     0                 1                 0   \n",
       "1                     0                 1                 0   \n",
       "2                     1                 1                 1   \n",
       "3                     1                 1                 1   \n",
       "4                     1                 0                 1   \n",
       "...                 ...               ...               ...   \n",
       "5045                  1                 1                 0   \n",
       "5046                  0                 1                 0   \n",
       "5047                  1                 1                 0   \n",
       "5048                  0                 0                 0   \n",
       "5049                  0                 1                 1   \n",
       "\n",
       "      bedroom_amenities  pet_amenities  convenience_amenities  \\\n",
       "0                     1              0                      0   \n",
       "1                     1              0                      1   \n",
       "2                     1              0                      1   \n",
       "3                     1              1                      1   \n",
       "4                     0              1                      1   \n",
       "...                 ...            ...                    ...   \n",
       "5045                  1              0                      0   \n",
       "5046                  1              1                      1   \n",
       "5047                  1              0                      1   \n",
       "5048                  0              0                      0   \n",
       "5049                  1              0                      1   \n",
       "\n",
       "      cleaning_amenities  service_amenities  smoking_amenities  work_amenities  \n",
       "0                      1                  1                  0               1  \n",
       "1                      0                  0                  0               1  \n",
       "2                      0                  0                  0               0  \n",
       "3                      1                  0                  0               1  \n",
       "4                      0                  0                  0               1  \n",
       "...                  ...                ...                ...             ...  \n",
       "5045                   0                  1                  0               1  \n",
       "5046                   1                  1                  0               0  \n",
       "5047                   1                  1                  0               1  \n",
       "5048                   0                  0                  0               1  \n",
       "5049                   0                  0                  0               1  \n",
       "\n",
       "[5050 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "categorical_var = listings.iloc[:, np.r_[5, 7, 9:12, 19:40]]\n",
    "categorical_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d4cb36",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z2/4cyvqbx576j0jhk55ggnz0sh0000gn/T/ipykernel_32893/2505525230.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtop_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     categorical_distribution = categorical_distribution.append({\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;34m'Variable'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m'Num_Missing'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_missing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m'Num_Unique'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_unique\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "categorical_distribution = pd.DataFrame()\n",
    "\n",
    "for column in categorical_var.columns:\n",
    "    num_missing = categorical_var[column].isnull().sum()\n",
    "    num_unique = categorical_var[column].nunique()\n",
    "    frequencies = categorical_var.groupby(column).size().reset_index(name='Frequency')\n",
    "\n",
    "    top_frequencies = frequencies.sort_values(by='Frequency', ascending=False).head(5)\n",
    "\n",
    "    categorical_distribution = categorical_distribution.append({\n",
    "        'Variable': column,\n",
    "        'Num_Missing': num_missing,\n",
    "        'Num_Unique': num_unique,\n",
    "        'Frequencies of levels': top_frequencies.set_index(column).to_dict()['Frequency']\n",
    "    }, ignore_index=True)\n",
    "\n",
    "categorical_distribution.set_index('Variable', inplace=True)\n",
    "\n",
    "categorical_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7625862",
   "metadata": {},
   "source": [
    "#### Airbnb Calendar Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "calendar = pd.read_csv('calendar_year.csv')\n",
    "calendar.iloc[:, 2:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1c7f5",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66946046",
   "metadata": {},
   "source": [
    "#### Dataset 1: Airbnb Listings\n",
    "\n",
    "The listings dataset contains information on Airbnb accommodations listed in Chicago, IL. \n",
    "\n",
    "<br />\n",
    "1. Selecting relevant columns\n",
    "<br />\n",
    "<br />\n",
    "    From the original listings dataset, we decided that we did not need the columns with long strings and paragraph-style descriptions of the listing and neighborhoods contained, or the urls and pictures of the listings. Therefore, we decided to keep only the columns that were relevant for our analyses: 'id', 'host_id', 'neighbourhood_cleansed', 'latitude', 'longitude', 'accommodates', 'amenities', 'price', 'host_response_time', 'host_response_rate', 'host_is_superhost', 'host_identity_verified', 'host_location', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value'.\n",
    "<br />\n",
    "<br />\n",
    "2. Missing values\n",
    "<br />\n",
    "<br />\n",
    "    We decided to drop rows with missing values rather than imputing them because from an analytical perspective, it was not likely to get reliable imputations from the methods in our toolkit. This is because there are so many factors and attributes that characterize each listing; for example, it would be inappropriate to impute a missing price value using the median value of neighborhood/location by latitude and longitude because the listings would still differ vastly in price depending on property/accommodation size or amenities offered. Dropping these rows was also justified by how most of the rows that had missing values to begin with tend to be new listings that are yet to be booked/reviewed. This is something we talked through with our mentor.\n",
    "<br />\n",
    "<br />\n",
    "3. Creating categorial variables for amenities (EDA 2)\n",
    "<br />\n",
    "<br />\n",
    "    In the original 'listings' dataset, each value of the 'amenities' column was a list of strings listing out every amenity that was offered at the airbnb property. We cleaned the dataset to make each amenity mentioned a categorical variable represented by the values 0 if not offered by the listing and 1 if offered by the listing. \n",
    "<br />\n",
    "<br />\n",
    " This process will be explained in further detail under the EDA 2 section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a06e1",
   "metadata": {},
   "source": [
    "#### Dataset 2: Airbnb Calendar\n",
    "\n",
    "The calendar dataset was available in the Airbnb data source as 4 separate csv files divded into each quarter of the year. \n",
    "To make the dataset appropriate for use in our analysis, we needed a calendar dataset spanning the entire year.\n",
    "\n",
    "To obtain this dataset, we found common listings that were included in each quarterly dataset, removed overlapping dates in each of the four quarterly datasets, and finally, concatenated them. This made it possible to track changes in prices for the same set of listings over the entire calendar year, particularly for the purposes of EDA 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c519e",
   "metadata": {},
   "source": [
    "#### Overall\n",
    "\n",
    "The steps described above were taken to create the cleaned Listings and Calendar dataset used in our analysis. \n",
    "\n",
    "Also,the initial listings dataset had significant price outliers. For example, in the summary statistics, the max value of price was 7585.00. Therefore, as part of our analysis, we filtered for price outliers using Tukey's fences in order to make sure that our visualizations showed trends without being obscured by the skew.\n",
    "    \n",
    "Note that rows that were dropped from the 'listings' dataset were also dropped correspondingly from the 'calendar' dataset (using the listing_ids) to streamline our analyses.\n",
    "\n",
    "Any further modifications made to the final dataset for respective EDA questions will be shown in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "For each analysis:\n",
    "\n",
    "What did you do exactly? How did you solve the problem? Why did you think it would be successful? \n",
    "\n",
    "What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work? \n",
    "\n",
    "Mention any code repositories (with citations) or other sources that you used, and specifically what changes you made to them for your project.\n",
    "\n",
    "Note that you can write code to publish the results of the code, but hide the code using the yaml setting `#|echo: false`. For example, the code below makes a plot, but the code itself is not published with Quarto in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e3664",
   "metadata": {},
   "source": [
    "### Analysis 1\n",
    "*By \\<Seoyeon Yoon>*\n",
    "\n",
    "#### What did you do exactly? How did you solve the problem? Why did you think it would be successful? What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?\n",
    "\n",
    "I wanted to investigate whether proximity from the City impacts the price of the listings. This would be a helpful information for the guests as they can make informed decisions based on their priorities (ex. being close to the city paying higher price vs. being budget-conscious). This information can benefit the hosts as well, as it shows the trends of the price within each area and how they should list their prices to have a competitive edge against other listings around them. So, I decided my EDA question to be: \"What is the correlation between the Proximity from the City and the Price of the listing?\". \n",
    "\n",
    "I solved my problem by mainly using the listings dataset. To start with, the dataset had a lot of columns, so we cleaned the dataset as well as condensed it to the columns we needed for this project. In addition to that, I created new columns using exisitng columns such as 'price per person', 'area', etc. 'price per person' was particularly crucial, allowing for a fair comparison of listings catering to different group sizes. 'area' was needed to categorize the lisitngs into respective neighborhoods in Chicago, especially because I am looking into pricing trends in each neighborhoods. Furthermore, recognizing the diversity of the dataset, a variety of visualization methods were strategically employed. Bar charts, scatter plots, and box-and-whisker plots were chosen based on their ability to effectively convey different aspects of the data.\n",
    "\n",
    "I thought this would be successful as I would be able to show whether proximity is one of the biggest influencing factor of pricing as there are many other factors that are considered when deciding the price. If there is a high correlation between price and proximity, it would mean proximity highly influences the price. If it is low, it means that there are other factors, which means that guests should balance out their priorities seeing what ix offered when staying in that airbnb, not only the proximity to maximize their utility.\n",
    "\n",
    "One problem I anticipated was how to show the relationships and my analysis using visualizations. As different visualization method serves different purposes, it was helpful to use multiple visualizations for the same sub-investigation to corroborate and better represent the findings (ex. for the first visualization, I used both bar chart and map scatter plot to showcase the same data). So, I overcame the anticipated challenge by using various visualisation methods. This approach not only enhanced the clarity of the findings but also ensured that the visualizations served distinct purposes.\n",
    "\n",
    "A challenge emerged when attempting to incorporate an additional dataset containing Chicago landmarks. As I realized that these landmarks were historical rather than tourist attractions, I made a change in my approach: instead of using the landmark dataset, I decided to pinpoint one coordinate, Millennium Park, as a representative point for tourist activity/ the core of the city.\n",
    "\n",
    "Overall, the analysis process was relatively smooth, mostly with what I initially thought of doing working. I believe the analysis process proved to be methodical and adaptable. The combination of data cleaning, variable creation, and a diverse set of visualizations contributed to a nuanced exploration of the correlation between proximity and Airbnb listing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbf6a2",
   "metadata": {},
   "source": [
    "#### Viz 1: Categorize Areas of Listing (Bar chart & Map plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd69731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "listings = pd.read_csv('./Datasets/listings_filtered.csv')\n",
    "\n",
    "#cleaning data and creating columns that are needed\n",
    "listings_dropped = listings.dropna()\n",
    "listings_dropped['price per person'] = listings_dropped['price']/listings_dropped['accommodates']\n",
    "\n",
    "listings_dropped['area'] = pd.np.select(\n",
    "    [\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Near North Side', 'Loop', 'Near South Side']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Ohare', 'Norwood Park', 'Edison Park', 'Jefferson Park', 'Forest Glen', 'North Park', 'Albany Park', 'Lincoln Square', 'Rogers Park', 'West Ridge', 'Edgewater', 'Uptown']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Chatham', 'Avalon Park', 'Burnside', 'Roseland', 'West Pullman', 'Pullman', 'Riverdale', 'South Deering', 'Hegewisch', 'East Side', 'South Chicago', 'Calumet Heights']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Ashburn', 'Auburn Gresham', 'Washington Heights', 'Beverly', 'Morgan Park', 'Mount Greenwood']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['North Center', 'Lake View', 'Lincoln Park', 'Logan Square', 'Avondale']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Dunning', 'Portage Park', 'Irving Park', 'Belmont Cragin', 'Hermosa', 'Montclare']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Bridgeport', 'Armour Square', 'Fuller Park', 'Douglas', 'Grand Boulevard', 'Oakland', 'Kenwood', 'Hyde Park', 'Woodlawn', 'South Shore', 'Greater Grand Crossing', 'Washington Park']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Mckinley Park', 'New City', 'Englewood', 'West Englewood', 'Chicago Lawn', 'West Lawn', 'Clearing', 'West Elsdon', 'Gage Park', 'Garfield Ridge', 'Archer Heights', 'Brighton Park']),\n",
    "        listings_dropped['neighbourhood_cleansed'].isin(['Austin', 'Humboldt Park', 'West Garfield Park', 'East Garfield Park', 'West Town', 'Near West Side', 'North Lawndale', 'South Lawndale', 'Lower West Side'])\n",
    "    ],\n",
    "    [\n",
    "        'Central',\n",
    "        'Far North Side',\n",
    "        'Far Southeast Side',\n",
    "        'Far Southwest Side',\n",
    "        'North Side',\n",
    "        'Northwest Side',\n",
    "        'South Side',\n",
    "        'Southwest Side',\n",
    "        'West Side'\n",
    "    ],\n",
    "    default='Other')\n",
    "\n",
    "ax = listings_dropped['area'].value_counts()[:25].plot.bar(ylabel = 'Number of listings', color='lightcoral')\n",
    "ax.yaxis.set_major_formatter('{x:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Coordinates of listings\n",
    "coordinates_listing = listings_dropped.iloc[:,5:7].to_numpy()\n",
    "\n",
    "#Millennium Park Coordinates\n",
    "mp_coord = np.array([41.8826, -87.6226])\n",
    "\n",
    "def listing_viz():\n",
    "    img = plt.imread(\"Chicago_Map.png\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 100),dpi=80)\n",
    "    fig.set_size_inches(20, 15)\n",
    "    ax.imshow(img,extent=[-87.960529, -87.475380, 41.629367, 42.036972])\n",
    "    plt.scatter(y = coordinates_listing[:,0], x = coordinates_listing[:,1], marker='o', color='lightcoral', zorder = 1)\n",
    "    plt.scatter(y = mp_coord[0],  x = mp_coord[1], marker='*', color = 'blue', s= 500, zorder = 2)\n",
    "    plt.xlim(-87.960529, -87.475380)\n",
    "    plt.ylim(41.629367, 42.036972)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "listing_viz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc5153",
   "metadata": {},
   "source": [
    "First I binned all the lisitngs in the dataset into respecitve neighborhoods by creating a column 'area'. Then, I used two visualization methods using the 'area' column. I first created the bar chart, but realized that although it shows the categorization and how much listings each neighborhood has, it does not show visually how they are distributed over the Chicago land. Therefore, I decided to make a scatterplot overlaid on the Chicago map to better visualize the geographical distribution.\n",
    "\n",
    "It shows that the majority of the listings are located on the Central/ North Side areas of Chicago. And the same can be deduced by seeing the scatter plot. Listings are less populated as it becomes farther away from the city area and as it goes to the South areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3947475",
   "metadata": {},
   "source": [
    "#### Viz 2: Listings in City vs. Residential Areas Price (Outlier-adjusted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# Calculate outliers using Tukey's method\n",
    "def tukey_outliers(series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return (series < lower_bound) | (series > upper_bound)\n",
    "\n",
    "# Identify outliers and count them for each area\n",
    "listings_dropped['outliers'] = tukey_outliers(listings_dropped['price per person'])\n",
    "\n",
    "outliers_by_area = listings_dropped.groupby('area')['outliers'].sum().reset_index()\n",
    "outliers_by_area = outliers_by_area.sort_values(by='outliers', ascending=False)\n",
    "\n",
    "# Create a bar plot for the number of outliers in each area\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x='area', y='outliers', data=outliers_by_area, palette='husl')\n",
    "plt.title('Number of Outliers in Each Area')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Number of Outliers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ca86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "wo_outliers = listings_dropped[listings_dropped['outliers'] == False]\n",
    "\n",
    "# Create a box plot for price in each area\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x='area', y='price per person', data=wo_outliers, palette='husl')\n",
    "plt.title('Price Variation in Each Area')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Price per Person')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55af8bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# Create a new column 'area_category' to distinguish residential and city areas\n",
    "listings_dropped['area_category'] = listings_dropped['area'].apply(lambda x: 'City' if x == 'Central' else 'Residential')\n",
    "wo_outliers = listings_dropped[listings_dropped['outliers'] == False]\n",
    "\n",
    "# Create a box plot for price comparison between residential and city areas\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='area_category', y='price per person', data=wo_outliers, palette='husl')\n",
    "plt.title('Price Comparison between Residential and City Areas')\n",
    "plt.xlabel('Area Category')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the median price per person for City and Residential areas\n",
    "median_price_city = listings_dropped[listings_dropped['area_category'] == 'City']['price per person'].median()\n",
    "median_price_residential = listings_dropped[listings_dropped['area_category'] == 'Residential']['price per person'].median()\n",
    "\n",
    "# Calculate the median price for all listings\n",
    "median_price_all = listings_dropped['price per person'].median()\n",
    "\n",
    "# Calculate the percentage change in price per person for City and Residential areas compared to the median\n",
    "percentage_change_city = ((median_price_city - median_price_all) / median_price_all) * 100\n",
    "percentage_change_residential = ((median_price_residential - median_price_all) / median_price_all) * 100\n",
    "\n",
    "print(f\"Percentage Difference in Price per Person for City compared to Overall Median: {percentage_change_city:.2f}%\")\n",
    "print(f\"Percentage Difference in Price per Person for Residential compared to Overall Median: {percentage_change_residential:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a32e1",
   "metadata": {},
   "source": [
    "Here, I identified the outlying prices by using Tukey's fence method. Shown from the bar chart, Central area has the most outlying prices, suggesting premium on locations near the city's core. This may because of the proximity to tourist attractions, expensive house pricings, etc. Also, it is known that the North half of Chicago is wealthier than the South half, which may be one reason why north area listings' price to be more expensive.\n",
    "\n",
    "After dropping all lisitngs with outlying prices, I created a box and whisker plot. The first box and whisker plot shows the price distribution for lisitngs grouped by each areas. Here, it is apparent that the Central area has a higher median and 25th, 75th percentile, as well as a wider price range. The general north area has a higher median price and wider range than the general south area. To make the comparison more obvious, I binned all the residential areas into a category called 'Residential' by creating a new column called 'area_category'. Although this may be less accurate as it is the average of all the areas except the Central area (City), it clearly shows the trend that lisitngs in the city have a higher overall price compared to the residential areas. The City having a wider IQR range shows that the central area has a more diverse range of prices, potentially with a mix of affordable and premium listings.\n",
    "\n",
    "I also calculated the percentage difference in price per person between city/ residential area and the overall median price per person to quanitfy the the trend. Here, we realize that city listings tend to be 45% more expensive compared to the overall median price and that the residential listings tend to be 7% cheaper than the overall median price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3cbbd",
   "metadata": {},
   "source": [
    "#### Viz 3: Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "distance_from_mp = np.sqrt(np.sum((mp_coord-coordinates_listing)**2,axis=1))\n",
    "\n",
    "distance_from_mp[distance_from_mp==0]=9999\n",
    "closest_coord_index = np.argmin(distance_from_mp)\n",
    "closest_coord_index\n",
    "\n",
    "\n",
    "closest_coord = coordinates_listing[closest_coord_index,:]\n",
    "closest_listing = listings_dropped.iloc[closest_coord_index, :]\n",
    "closest_listing\n",
    "\n",
    "\n",
    "farthest_coord_index = np.argmax(distance_from_mp)\n",
    "farthest_coord = coordinates_listing[farthest_coord_index, :]\n",
    "farthest_listing = listings_dropped.iloc[farthest_coord_index, :]\n",
    "\n",
    "coordinates_listing[168,:]\n",
    "\n",
    "listing_coord = np.array((closest_coord, farthest_coord))\n",
    "\n",
    "# add new column of the distance between listings and the Millennium Park\n",
    "distance_from_mp = np.sqrt(np.sum((mp_coord - np.array(listings_dropped[['latitude', 'longitude']])) ** 2, axis=1))\n",
    "listings_dropped['distance_from_mp'] = distance_from_mp\n",
    "\n",
    "#scatterplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='distance_from_mp', y='price per person', hue='area_category', data=listings_dropped, alpha=0.6)\n",
    "\n",
    "#Regression line for City\n",
    "sns.regplot(x='distance_from_mp', y='price per person', data=listings_dropped[listings_dropped['area_category'] == 'City'], scatter=False, color='red', label='City')\n",
    "\n",
    "#Regression line for Residential\n",
    "sns.regplot(x='distance_from_mp', y='price per person', data=listings_dropped[listings_dropped['area_category'] == 'Residential'], scatter=False, color='blue', label='Residential')\n",
    "\n",
    "plt.title('Correlation between Proximity to Millennium Park and Price')\n",
    "plt.xlabel('Distance from Millennium Park')\n",
    "plt.ylabel('Price per Person')\n",
    "plt.legend(title='Area Category', loc='upper right')\n",
    "\n",
    "#Pearson coeff for City\n",
    "correlation_city = listings_dropped[listings_dropped['area_category'] == 'City']['distance_from_mp'].corr(listings_dropped[listings_dropped['area_category'] == 'City']['price per person'])\n",
    "print(f\"Pearson Correlation Coefficient for City: {correlation_city}\")\n",
    "\n",
    "#Pearson coeff for Residential\n",
    "correlation_residential = listings_dropped[listings_dropped['area_category'] == 'Residential']['distance_from_mp'].corr(listings_dropped[listings_dropped['area_category'] == 'Residential']['price per person'])\n",
    "print(f\"Pearson Correlation Coefficient for Residential: {correlation_residential}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b2782",
   "metadata": {},
   "source": [
    "In this scatterplot, I first calculated the euclidean distance of each of the listings from the Millennium Park. The x-axis is the distance from the Millennium Park, and the y-axis is the price per person for each lisitngs. I also included a trendline using regplot to visualize the correlation between the two variables.\n",
    "\n",
    "To dive deeper into the Pearson correlation coefficients, both of the area categories have a negative correlation, which means that as the distance from the Millennium Park increases, the price per person tends to decrease. We can guage the strength of the correlation by seeing the absolute values of the correlation coefficient. City has a weak to moderate magnitude (-0.3181), which we can conclude that it has a discernable downward trend. The residential area has a weak magnitude (-0.1771). Therefore, we can conclude that though correlation exists, since they are not strong, distance to the city is a factor, but not the sole and most important factor that determines the price of the listing. There may be other factors that are incorporated in the process of deciding the price. This ultimately answers and concludes my EDA question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a138840",
   "metadata": {},
   "source": [
    "#### Viz 4: Seasonal Booking Rate within respective areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "calendar = pd.read_csv('./Datasets/calendar_year.csv')\n",
    "one_year_ago = pd.Timestamp('2023-09-12') - pd.DateOffset(years=1)\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "\n",
    "holidays = {\n",
    "    'Easter': ['04-04', '04-05', '04-06'],\n",
    "    'Summer Vacation': ['06-01', '08-31'],\n",
    "    'Thanksgiving': ['11-25', '11-26', '11-27'],\n",
    "    'Christmas': ['12-24', '12-25', '12-26']\n",
    "}\n",
    "\n",
    "holiday_dates = [date for dates in holidays.values() for date in dates]\n",
    "holiday_data = calendar[(calendar['date'].dt.strftime('%m-%d').isin(holiday_dates)) & (calendar['available'] == 't')]\n",
    "\n",
    "holiday_data_with_area = pd.merge(holiday_data, listings_dropped[['listing_id', 'area']], left_on='listing_id', right_on='listing_id', how='inner')\n",
    "\n",
    "booking_rates_holidays = 100 * (holiday_data_with_area.groupby(['area']).size()/3) / listings_dropped.groupby('area').size()\n",
    "\n",
    "booking_rates_holidays_sorted = booking_rates_holidays.sort_values(ascending=False)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=booking_rates_holidays_sorted.index, y=booking_rates_holidays_sorted.values, palette='husl')\n",
    "plt.title('Booking Rates During Holidays by Area')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Booking Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e55e3",
   "metadata": {},
   "source": [
    "This plot was not included in the presentation for the sake of time and flow of the presentation. However, I would like to include this in the report as this visualization also gives valuable information that may be useful. Here, I used the calendar dataset as well as the lisitngs dataset. I joined the two dataset by merging them on the 'listing_id' column where both dataset shares. I wanted to know which areas are booked the most during holiday seasons, which consists of Easter, Summer Vacation, Thanksgiving, and Christmas, where people travel a lot to visit friends and families. The bar plot shows that people use the lisitngs in the North/West/Northwest sides and Central areas the most in these seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd19670",
   "metadata": {},
   "source": [
    "### Analysis 2\n",
    "*By Christine Kim*\n",
    "\n",
    "#### What did you do exactly? How did you solve the problem? Why did you think it would be successful? What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?\n",
    "\n",
    "I was interested in the disparities in amenity offerings between different airbnbs. Especially from the perspectives of the hosts, I wanted to solve the problem of what amenities they should offer depending their target price to charge for the listing or to gain a higher revenue. Therefore, this section revolves around the question: Are there associations between Amenities and the Price of the listing? \n",
    "\n",
    "I thought that analyzing the data around this EDA question would be able to solve the hosts problems by offering insight into which amenities are the most/least common or associated with higher/lower prices. Ultimately, from the standpoint of hosts who want to be able to charge higher prices on their listings to gain more revenue, this analysis could form valuable insights into which amenities hosts should focus on offering.\n",
    "\n",
    "A major challenge that I anticipated and encountered was the data cleaning process for the amenities column in the listings dataset. In the original 'listings' dataset, each value of the 'amenities' column was a list of strings listing out every amenity that was offered at the airbnb property. I cleaned the dataset to make each amenity mentioned a categorical variable represented by the values 0 if not offered by the listing and 1 if offered by the listing. However, a problem that I faced was that doing this resulted in 2428 columns of amenity categorical variables. This was because variations in spelling or description of the same amenity led to the creation of multiple variables. For example, \"body wash\" or \"body soap\" or \"shower gel\" are three variations of the same amenity. \n",
    "\n",
    "To overcome this challenge, I tried multiple methods such as renaming columns that contained the same word as that word (e.g. \"Pantene shampoo\" and \"Dove shampoo\" renamed as \"shampoo\"), but even this resulted in an exorbitant number of amenity categorical variables that were unable to be visually represented in a clear way. \n",
    "Finally, the method that I found worked best was to use keywords to categorize each amenity into a category. By this method, I was able to categorize most amenities, excluding those that were too obscure and were only offered by less than 1% of all the listings, into 21 distinct amenity categories, and correspondingly, 21 amenity categorical variables columns in the cleaned dataset. \n",
    "\n",
    "These amenity categories represent descriptions as follows:\n",
    "   - 'wifi_amenities': wifi\n",
    "   - 'bathroom_amenities': amenities including shampoo, body wash, conditioner, and hair dryer\n",
    "   - 'kitchen_amenities': amenities including refrigerator, microwave, oven, stove, dishwasher, kettle, silverware, etc.\n",
    "   - 'leisure_amenities': amenities including tv channels, games, books, sound systems, etc.\n",
    "   - 'laundry_amenities': amenities including washers, dryers, irons, etc.\n",
    "   - 'storage_amenities': amenities including storage space such as closets and dresssers\n",
    "   - 'transporation_amenities': amenities including parking spaces, garage, ev chargers\n",
    "   - 'environment_amenities': amenities including heaters, air conditioning, fans, etc.\n",
    "   - 'safety_amenities': amenities including first aid kits, fire alarms, fire extinguishers, security cameras, etc.\n",
    "   - 'exercise_amenities': amenities including gyms, treadmills, weights, yoga mats, etc.\n",
    "   - 'views_amenities': amenities including different views and lake/beach access\n",
    "   - 'outdoor_amenities': amenities including patios, yards, hammocks, sun loungers, etc.\n",
    "   - 'luxury_amenities': amenities including hot tubs, pools, sauna, rooftops, etc.\n",
    "   - 'family_amenities': amenities including children/baby-related equipment such as cribs, high chairs, changing tables, etc.\n",
    "   - 'bedroom_amenities': amenities including blankets, pillows, bedlinens\n",
    "   - 'pet_amenities': allowing pets\n",
    "   - 'convenience_amenities': amenities including self check-ins, luggage services, and elevators\n",
    "   - 'cleaning_amenities': amenities including cleaning products and trash\n",
    "   - 'service_amenities': amenities including cleaning services, breakfast included, building staff access\n",
    "   - 'smoking_amenities': allowing smoking\n",
    "   - 'work_amenities': amenities including workspace/desks  \n",
    "\n",
    "\n",
    "Given the cleaned data I tried to analyze my question: Are there associations between Amenities and the Price of the listing?\n",
    "\n",
    "I first looked at the variety of amenities offered at an accommodation against its listing price. By intuition, my hypothesis was that offering a greater variety of amenities might be associated with higher pricces, since these listings would attract customers who are looking for better equipped airbnbs despite a higher price per night. I anticipated that it would be hard to see trends across over 5000 listings; thus, I decided to bin the listings into \"High prices\" and \"Low prices\" categories, which respresented listings that charged above the median price/night and listings that charged below the median price/night, respectively. Also, since there are 21 different amenity categories, I decided to focus less the specific amenity categories and more on the number of amenity categories offered, for the simplicity and readability of my first visualization, as well as to capture the distinct trend associated with offering a larger variety of amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "listings = pd.read_csv('listings_filtered.csv')\n",
    "\n",
    "# Removing price outliers\n",
    "q1 = np.percentile(listings['price'],25)\n",
    "q3 = np.percentile(listings['price'],75)\n",
    "intQ_range = q3-q1\n",
    "\n",
    "#Tukey's fences\n",
    "Lower_fence = q1 - 1.5*intQ_range\n",
    "Upper_fence = q3 + 1.5*intQ_range\n",
    "\n",
    "Outlying_obs = listings[(listings.price<Lower_fence) | (listings.price>Upper_fence)]\n",
    "Outlying_obs\n",
    "\n",
    "listings_nooutlier = listings.drop(Outlying_obs.index)\n",
    "listings_nooutlier.describe()\n",
    "\n",
    "median_price_threshold = listings_nooutlier['price'].quantile(0.5)\n",
    "\n",
    "listings_nooutlier['amenity_count'] = listings_nooutlier.iloc[:, listings_nooutlier.columns.get_loc('wifi_amenities'):listings_nooutlier.columns.get_loc('work_amenities') + 1].sum(axis=1)\n",
    "\n",
    "# Bin into high and low prices\n",
    "high_prices = listings_nooutlier[listings_nooutlier['price'] > median_price_threshold]['amenity_count']\n",
    "low_prices = listings_nooutlier[listings_nooutlier['price'] <= median_price_threshold]['amenity_count']\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax1 = sns.histplot(high_prices, color=\"lightcoral\", label='High Prices', kde=False)\n",
    "ax2 = sns.histplot(low_prices, color=\"lightblue\", label='Low Prices', kde=False)\n",
    "plt.xlabel('Number of Amenity Categories')\n",
    "plt.ylabel('Number of Listings')\n",
    "ax1.set_xticks(np.arange(0,21,1))\n",
    "plt.title('Number of Amenity Categories offered by High vs. Low Priced Listings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e511d0",
   "metadata": {},
   "source": [
    "I found a distinct association from the plot which showed that, as the number of distinct amenity categories offered increased, so do the number of listings priced above the median relative to the number of listings priced below the median. More specifically, the plot shows that a greater proportion of listings that offer 13 or more different amenity cateogires are associated with higher prices than with lower prices, with the greatest relative difference at 16 amenity categories. The result was somewhat surprising to me as the variety of amenity categories offered tended to be greater than I expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329fdd26",
   "metadata": {},
   "source": [
    "In my first plot, I show the association between the variety of amenities offered and the price category and it seems that offering up to 12 different amenities categories is more prevalent in listings below the median price. This result prompted the question around specific amenity categories, and I wanted to distinguish which amenity cateogires are the ones that matter. Thus, in my second plot, I show the prevalence of each amenity category across listings in the dataset. I thought that this would help me discern those amenity categories offered across most listings regardless of price against the more selectively offered amenity categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "amenities_count = listings_nooutlier.iloc[:, listings_nooutlier.columns.get_loc('wifi_amenities'):listings_nooutlier.columns.get_loc('work_amenities') + 1].sum().sort_values(ascending=False)\n",
    "\n",
    "amenity_categories = list(amenities_count.index)\n",
    "\n",
    "percentages = listings_nooutlier[amenity_categories].mean() * 100\n",
    "sorted_percentages = percentages.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sorted_percentages.plot(kind='bar', color='lightcoral')\n",
    "plt.title('Percentage of Listings Offering Each Amenity Category')\n",
    "plt.xlabel('Amenity Category')\n",
    "plt.ylabel('Percentage of Listings (%)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92826f76",
   "metadata": {},
   "source": [
    "From my second plot, I found that environmental_amenities, safety_amenities, wifi_amenities, kitchen_amenities, and laundry_amenities were offered nearly ubiquitously across all listings in the dataset. The high prevalence of these amenities suggest that most airbnb hosts in Chicago already offer them, and this might suggest that these amenities are considered essential in airbnbs. On the other hand, there are other amenity categories with a lower proportion of listings that offer them and tend to be relatively less commonly offered in airbnbs in Chicago.\n",
    "\n",
    "Thus, my analysis and visualizations up to this point show that listings in Chicago that offer a greater variety of amenity categories are more likely to associated with prices higher than the median price, but that there are also some essential amenities and some selective amenties. This motivated the question then, out of the less common amenity cateogires, which ones should the host prioritize offering to maximize their revenue increase?\n",
    "\n",
    "Therefore, for my third visualization, I examined the average price increase relative to the mean price that is associated with offering a specific amenity category. I thought that showing the achievable average increase in price after offering an amenity category would add value to analyzing my EDA question of association of amenities to prices, as well as to solving the larger problem of what amenities hosts should offer to earn a higher revenue from their listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "overall_average_price = listings_nooutlier['price'].mean()\n",
    "\n",
    "# Dictionary to store the price differential for each amenity\n",
    "price_differential = {}\n",
    "\n",
    "# Iterate over each amenity category to calculate the average price and price differential\n",
    "for amenity_category in amenity_categories:\n",
    "    has_amenity = listings_nooutlier[listings_nooutlier[amenity_category] == 1]['price'].mean()\n",
    "    price_differential[amenity_category] = has_amenity - overall_average_price\n",
    "\n",
    "sorted_differential = pd.Series(price_differential).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sorted_differential.plot(kind='bar', color='lightcoral', ax=ax)\n",
    "ax.set_title('Average Price Increase from offering an Amenity Category')\n",
    "ax.set_xlabel('Amenity Category')\n",
    "ax.set_ylabel('Average Price Increase ($)')\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "\n",
    "# Annotate bars with the value of the price differential\n",
    "for i, v in enumerate(sorted_differential):\n",
    "    ax.text(i, v if v > 0 else 0, f\"${v:.2f}\", color='black', ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa816a9",
   "metadata": {},
   "source": [
    "From the plot, we see an interesting trend that offering the more prevalent, \"essential\" amenity categories identified from my second plot is associated with the smallest average price increase relative to the mean price of almost 0. On the other hand, out of the less commonly offered amenities, views_amenities and family_amenities are associated with the largest average price increase, followed by exercise_amenities and storiage amenities, at approximately ~$30 per night."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b33ebc",
   "metadata": {},
   "source": [
    "Analyzing the results from my visualizations collectively, my analysis suggests that it would be beneficial for the hosts from a price standpoint to offer more amenity categories than less, if feasible. In terms of considering the amenity categories and their associations with price, adding more amenities categories in order of the highest price increases from plot 3 would maximize the correlation of their listings with charging higher prices per night. As hosts add their amenity category offerings, they also should keep in mind that while association with higher prices does increase as more variety of amenity categories are offered, the majority of listings that offer 13 or more distinct amenity categories are associated with prices above the median.\n",
    "\n",
    "I did not use any code repositories or other sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bf52e",
   "metadata": {},
   "source": [
    "### Analysis 3\n",
    "*By Zindeh Scere*\n",
    "\n",
    "##### What did you do exactly? How did you solve the problem? Why did you think it would be successful? What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?\n",
    "\n",
    "I was interested in learning about how the behavior and traits of the hosts influence the rating and experience of customers. This is useful information for hosts who want to receive the best possible scores from customers and/or are looking for ways to improve the customer's overall experience. This information can also be useful for customers who are searching through listings and are interested in finding reliable hosts. Therefore, this section focuses on the question: Are there associations between Host Attributes and Booking Satisfaction?\n",
    "\n",
    "By glancing at the dataset, I initially thought that by examining the host's response times and rates, hosts with quick response times and high rates would likely have strong customer reviews because of the effort put in to communicate with customers. I wanted to see which rates and times got the most positive reviews from customers. I anticipated that because I was working with a combination of categorical and continuous variables, I might have some issues with data cleaning and data wrangling. Preemptively, I created dummy variables to find correlations and search for ways to best visualize categorical variables. However, my first point of analysis ended up causing a challenge due to the limited number of insights it produced and the disparity in the amount of data points. \n",
    "\n",
    "To begin, I converted host_response_rate to a float and divided it by 100 to make it into a decimal. Previously, the values were whole numbers that weren't numerically representative of the rates. Converting the values into a decimal made for easier analysis as they could better represent the fraction of time (rates) being analyzed. Next, I used groupby to create groups for host_response_time as it was a categorical variable that I wanted to evaluate with continuous variables. I first looked at the mean of each response rate for each value group within host_response_time. I then plotted the mean values using a bar graph. \n",
    "\n",
    "Although the data was intuitive (those with quicker response times, had higher response rates), there were a couple of issues with the visualization. One, there wasn't much variability within the data. There was minimal difference between the mean rate for within a few hours (97.9%), and within an hour (99.32%). While there was a significant difference between a few days or more (15.17%) and the rest of the data, when I looked at the distribution of the values for each category, there was a huge skew in the distribution of value counts. A few or more days seemed to have a significantly lower number of data points (152 values vs within an hour which had 6589)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e5f61",
   "metadata": {},
   "source": [
    "###### Host response time vs host response rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becff16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "listings.host_response_rate = listings.host_response_rate.astype(float)/100\n",
    "\n",
    "sns.barplot(data = listings, x = 'host_response_rate', y = 'host_response_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09572e47",
   "metadata": {},
   "source": [
    "##### Distribution of host response time variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8318e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "a = sns.catplot(data = listings, x = 'host_response_time', kind = 'count',)\n",
    "a.set_axis_labels(\"Host Response time\", \"Count\")\n",
    "a.set_xticklabels(rotation=30) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd65c1",
   "metadata": {},
   "source": [
    "I decided to attempt to plot the relationship between host response times and customer review ratings and found a similar outcome: little variability (this time even less) between mean overall customer ratings—making this a limited analysis to give back to the stakeholders. Again, because of the wide difference in the count between the categories, it's difficult to confidently tell stakeholders that it seems that response time might not influence customer response rating. The plot below makes it seem like there is little variability but when considering the variability within the count of each value (see plot above), the number of values for each group is too varied to confidently assess the potential insignificance of the relationship that is plotted below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44101092",
   "metadata": {},
   "source": [
    "##### Host response time vs Customer review rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10723366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "sns.barplot(data = listings, x = 'review_scores_rating', y = 'host_response_time')\n",
    "plt.title('Host Response Time vs Customer Review Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc50c21",
   "metadata": {},
   "source": [
    "Furthermore, using dummy variables, I was able to confirm my analysis by finding what seemed to be low positive and negative correlations between the variable host_response_rate and overall rating.\n",
    "\n",
    "While these findings may indicate that quick responses could lead to faster response rates and that response time has a minimal relationship with overall rating, due to the distribution of the count of the values, I couldn't make a confident analysis and instead decided to find other ways to explore my question. So, I pivoted my approach to the question and instead looked at what host attributes outside of response rate and time were receiving the best feedback from customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075117ec",
   "metadata": {},
   "source": [
    "##### Correlation outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20717ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "dummy = pd.get_dummies(listings.host_response_time)\n",
    "print('Correlation between Host Response Time and Rate:\\n', dummy.corrwith(listings.host_response_rate), '\\n', '\\n'\n",
    "      'Correlation between Host Response Time and Overall Rating:\\n', \n",
    "      dummy.corrwith(listings.review_scores_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c31756",
   "metadata": {},
   "source": [
    "Back in the dataset, I decided to search for more broad attributes and looked for relationships between them and the review categories. Host location stood out to me and when I printed out the unique variables, I was shocked to find a wide variety of locations for hosts. I had anticipated that many of the listing hosts would reside in Chicago but had thought that most hosts outside of Chicago would live in the Chicagoland area. I found that there were 168 unique locations of hosts, many being far from Chicago. This made me curious as to how the location of a host might influence customer reviews. I first printed the value counts for each location and found that there was some variability in how people listed their location. For example, some people listed their location as \"United States,\" others listed their state, and other hosts listed their city and state. Some even listed a different country! There were so many locations that I decided it might be best to focus on the 10 ten. Initially, within the top ten, there were values such as “United States” and “Illinois, United States.” Since none of the other locations in the top 10 were countries, I decided to drop \"United States\" because while there are 55 inputs, it may cause repetition or confusion. Additionally, all the other locations in the list were within the US so it might not make sense to have the United States show up again. I also got rid of inputs that were only \"Illinois, United States\" because, like the United States, many of the other locations were in Illinois and would potentially add repetition to the data as there was no way to distinguish between the two. I thought about creating a new category but felt that there wasn't a way to fully encompass the repetition. So, I created a list of the top 10 cities (a requirement that excludes countries and states) that hosts listed. After that, I created a bar plot to show the relationship between a host's location and the mean overall rating received for hosts in that location. I learned that the host location with the highest mean overall rating is Tampa, FL. I also learned that Chicago’s mean overall rating was 6th. This finding may be because more hosts live in Chicago so they might have more variability due to their count, nevertheless, the mean ratings showed much diversity in both rating and location. This became my first visualization to present to stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086c4ef",
   "metadata": {},
   "source": [
    "#### Visualization 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdce666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "top_5 = listings.host_location.value_counts()>=10\n",
    "top_5_loc = listings.loc[listings.host_location.isin(top_5[top_5].index.to_list()),:]\n",
    "\n",
    "list_loc = top_5_loc[['host_location', 'review_scores_rating']].groupby('host_location').mean()\\\n",
    ".drop(['United States', 'Illinois, United States']).sort_values(by = 'review_scores_rating', \n",
    "                                                                ascending= False).index.to_list()\n",
    "sns.barplot(x = 'review_scores_rating', y = 'host_location', data=listings, order=list_loc)\n",
    "plt.ylabel('Host Location')\n",
    "plt.title('Host Location vs Mean Overall Rating')\n",
    "plt.xlabel('Mean Overall Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0eb5b",
   "metadata": {},
   "source": [
    "From the above plot, I found that cities outside of Chicago and in the case of the top 2, cities outside of Illinois, had a higher mean overall rating. This felt like a useful insight to present to hosts and customers: location doesn't necessarily negatively impact the host's ability to attain a high mean overall score. The high mean scores come from a variety of geographical locations. This gives confidence to hosts who might choose to move outside of Chicago and to customers who might be concerned about a host who is outside of Chicago being able to support them throughout their stay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77bf74",
   "metadata": {},
   "source": [
    "Next, I made several scatter plots focused on looking at how traits such as having a profile picture, having a verified identity, and being a super host influence the overall rating and host response rate relative to specific rating factors such as communication, accuracy, and check-in. I did this because I wanted to know what specific digital attribute hosts should focus on when working to push their listings on the website. I also felt this information would be helpful for customers to consider as they searched for reliable hosts that may be likely to ensure their satisfaction during the booking. Since these host attribute columns were booleans, I used a facet grid to compare the outcomes of each boolean. For example, for super hosts, I examined the relationship between overall rating and review accuracy. This was useful in thinking about how a super host’s overall ratings are impacted by how customers perceive the accuracy of their listing. The findings from these plots revealed several things. First, while there was a bit of noise in the graph, it did exemplify that being a super host did seem to matter. Hosts who were super hosts seem to display a closer linear relationship indicating a possible strong correlation. Second, within my super host plots, their review factors seem to have a stronger relationship with their overall rating. Additionally, I also did a similar graph with host response rate and overall rating. This showed a similar outcome: super hosts were more likely to have a higher response rate which had a strong positive relationship with their overall rating. These Findings seem beneficial to stakeholders. Of the digital attributes available to analyze, being a super host seems to be the most impactful, and super hosts seem to consistently perform well with their review factors and response rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9b2b8",
   "metadata": {},
   "source": [
    "#### Visualization 2: \n",
    "##### Overall rating vs Accuracy (Superhosts vs not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aadb8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "a = sns.FacetGrid(listings, col = 'host_is_superhost', col_wrap = 2)\n",
    "a.map_dataframe(sns.regplot, x = 'review_scores_accuracy', y = 'review_scores_rating', scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"blue\"})\n",
    "a.set_titles(col_template= 'Superhost: {col_name}')\n",
    "\n",
    "a.set_xlabels('Accuracy Rating')\n",
    "a.set_ylabels('Overall Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f0b3b",
   "metadata": {},
   "source": [
    "##### Overall rating vs Check in (Superhosts vs not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c674be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "c = sns.FacetGrid(listings, col = 'host_is_superhost', col_wrap = 2)\n",
    "c.map_dataframe(sns.regplot, x = 'review_scores_checkin', y = 'review_scores_rating', scatter_kws={\"color\": \"lightcoral\"}, line_kws={\"color\": \"blue\"})\n",
    "c.set_titles(col_template= 'Superhost: {col_name}')\n",
    "\n",
    "c.set_xlabels('Check-in Rating')\n",
    "c.set_ylabels('Overall Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921e086",
   "metadata": {},
   "source": [
    "##### Overall rating vs Communication (Superhosts vs not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589f74f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "b = sns.FacetGrid(listings, col = 'host_is_superhost', col_wrap = 2)\n",
    "b.map_dataframe(sns.regplot, x = 'review_scores_communication', y = 'review_scores_rating', scatter_kws={\"color\": \"purple\"}, line_kws={\"color\": \"blue\"})\n",
    "b.set_titles(col_template= 'Superhost: {col_name}')\n",
    "b.set_xlabels('Communication Rating')\n",
    "b.set_ylabels('Overall Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068ce2c",
   "metadata": {},
   "source": [
    "##### Host response rate vs overall rating (Superhosts vs not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "f = sns.FacetGrid(listings, col = 'host_is_superhost', col_wrap = 2)\n",
    "f.map_dataframe(sns.regplot, x = 'review_scores_accuracy', y = 'host_response_rate', scatter_kws={\"color\": \"green\"}, line_kws={\"color\": \"blue\"})\n",
    "f.set_titles(col_template= 'Genre: {col_name}')\n",
    "\n",
    "f.set_ylabels('Host Response Rate')\n",
    "f.set_xlabels('Overall Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4914e",
   "metadata": {},
   "source": [
    "Finally, looking at the seemingly strong relationship between overall rating and various customer review factors, I wanted to know whether a host's attribute or key factors for review had the strongest correlation with a customer's overall rating. This felt useful in understanding which potential element seemed to have the strongest correlation with a customer's overall satisfaction (represented by their overall rating) throughout their experience on Airbnb. Since I was looking at the correlation between multiple factors, I decided a heatmap might be the best way to visualize this. To do this, I first created a subset of variables that included both host attributes and various types of review ratings. I then created dummy variables for the categorical variables and mapped the correlation of all the variables. Through this visualization, I found that while being a super host did seem to have a strong correlation to a customer's overall rating, it was significantly outperformed by review factors such as communication, check-in, and accuracy. My analysis suggests that as hosts aim to ensure that customers have the best experience possible, their attributes may have less of an influence than other factors such as customers' perception of the cleanliness of a listing, the accuracy of the listing description, and the effectiveness of their communication.\n",
    "\n",
    "I did not use any code repositories or sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3b66d",
   "metadata": {},
   "source": [
    "#### Visualization 3:\n",
    "##### Mapping correlation between host attributes and review factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "vals = listings.loc[:,['host_identity_verified', 'host_response_rate', 'host_is_superhost', 'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee45e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "sns.heatmap(pd.get_dummies(vals).corr())\n",
    "plt.title('Correlation Between Host Attributes and Rating Factors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70d20c",
   "metadata": {},
   "source": [
    "### Analysis 4\n",
    "*By \\<Name of person doing the analysis>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6026cb7",
   "metadata": {},
   "source": [
    "## Other sections\n",
    "\n",
    "You are welcome to introduce additional sections or subsections, if required, to address your questions in detail. For example, you may briefly discuss potential future work that the research community could focus on to make further progress in the direction of your project's topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Do the individual analysis connect with each other to answer a bigger question? If yes, explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e41b2a",
   "metadata": {},
   "source": [
    "## Recommendations to stakeholder(s)\n",
    "What are the action items for the stakeholder(s) based on your analysis? Be as precise as possible. The stakeholder(s) are depending on you to come up with practically implementable recommendations, instead of having to think for themselves.\n",
    "\n",
    "Do the stakeholder(s) need to be aware about some limitations of your analysis? Can your analysis be directly used by the stakeholder(s) to obtain the expected benefit / make decisions, or do they need to do some further analysis based on their own, or do they need to repeat your analysis on a more recent data for the results to be applicable? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c395c",
   "metadata": {},
   "source": [
    "#### Analysis 2\n",
    "\n",
    "New hosts should first ensure that essential amenities (environmental controls, safety, wifi, kitchen amenities) are provided. Given that the essential amenities are offered, hosts should consider offering the most value-adding amenities (views, family-friendly, exercise, and storage) at an increased price point (~$30). Specifically, if hosts are already looking to add more amenity categories to their listings, offering 13 or more distinct categories seem to be more strongly associated with charging higher prices than offering 12 or less.\n",
    "\n",
    "The hosts should be aware about some limitations of the analysis, such as that the recommendations are based on broadly defined amenity categories and does not always recommend specifically which item within the amenity category they should offer (e.g. differentiate between lake view and beach view). However, the analysis can still be directly used by hosts in Chicago to obtain the expected revenue benefit of around $30 per night, especially if their listings have entire amenity categories that are not yet offered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea84c9",
   "metadata": {},
   "source": [
    "#### Analysis 3\n",
    "\n",
    "Hosts should strive for positive reviews, responsiveness, and minimal cancellations (qualifications of a super host) to become a super host. This seems to be an impactful attribute in relation to a customer's booking satisfaction. However, to increase their likelihood of higher booking satisfaction and reviews, hosts should focus on clear communication, listing description accuracy, smooth check-ins, and cleanliness of their listings. This will allow them to be 72-85% more likely to receive strong booking satisfaction. Similarly, when searching for a listing, customers should review a host's communication, accuracy, check-in, and cleanliness rating as this seems to have a strong correlation to the overall booking satisfaction of their previous customers.\n",
    "\n",
    "Customers and stakeholders should be aware that there are limitations to this analysis as greater investigation might be needed to explore what—if any—confounding might be playing a role in the correlations found in these findings. Additional research may also be needed to find causality as correlation only speaks to the statistical relationships found between the variables within this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1cafe",
   "metadata": {},
   "source": [
    "## References {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb1aad",
   "metadata": {},
   "source": [
    "List and number all bibliographical references. When referenced in the text, enclose the citation number in square brackets, for example [1].\n",
    "\n",
    "[1] Authors. The frobnicatable foo filter, 2014. Face and Gesture submission ID 324. Supplied as additional material\n",
    "fg324.pdf. 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831751c",
   "metadata": {},
   "source": [
    "## Appendix {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d374d",
   "metadata": {},
   "source": [
    "You may put additional stuff here as Appendix. You may refer to the Appendix in the main report to support your arguments. However, the appendix section is unlikely to be checked while grading, unless the grader deems it necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
